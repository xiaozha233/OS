# **Lab2: 物理内存管理与页表 实验报告**

**小组成员:** 

| 姓名  | 学号      | 任务分工        |
| :-- | :------ | :---------- |
| 陈翔  | 2314035 | 完成练习2解答以及challenge2     |
| 查许琴 | 2314076 | 完成练习1,2解答以及challenge1     |
| 刘璇  | 2313255 | 完成练习2，实验知识点总结内容以及challenge3 |

**实验日期:** 2025年10月

## **一、 实验目的与内容概述**

### **1.1 实验目的** 

本次实验的核心目标是深入理解并亲手实现操作系统的物理内存管理。具体目的包括：
1.  **理解页表的建立和使用方法**：掌握如何通过构建页表，实现从虚拟地址到物理地址的映射，为现代操作系统的内存隔离与虚拟化打下基础。
2.  **理解物理内存的管理方法**：学习操作系统如何探测、组织和追踪物理内存资源，特别是以页为单位的管理方式。
3.  **理解页面分配算法**：通过分析和实现 First-Fit 及 Best-Fit 算法，掌握连续物理内存分配的核心策略与权衡。

### **1.2 实验内容** 

本实验在 `lab1` 可启动系统的基础上，重点实现了物理内存管理模块（PMM）。主要内容分为两大块：

1.  **建立分页机制**：修改内核的启动流程 (`entry.S`)，通过创建一个临时的启动页表，将内核自身映射到高虚拟地址空间，并成功开启 MMU 的分页模式。这使得内核后续可以在虚拟地址空间中运行。
2.  **实现物理内存分配**：设计并实现了一个物理内存管理器，它能够：
    *   探测可用的物理内存范围。
    *   使用 `struct Page` 数组来描述和管理所有物理页。
    *   通过链表来组织空闲的物理内存块。
    *   实现并测试了 First-Fit 和 Best-Fit 两种经典的连续内存分配算法。

## **二、 练习解答**

### **练习1：理解 first-fit 连续物理内存分配算法（思考题）**

#### **1. 物理内存分配过程与函数作用分析**
First-Fit (首次适应) 算法的实现位于 `kern/mm/default_pmm.c` 中，其核心思想是：在收到内存分配请求时，从空闲内存块链表的头部开始查找，将**第一个**大小足够满足请求的空闲块分配出去。如果该块大于请求大小，则将其分裂，剩余部分作为新的小空闲块放回链表。

整个物理内存分配的生命周期由以下几个关键函数协同完成：

1.  **`default_init()`**:
    *   **作用**：初始化物理内存管理器。
    *   **过程**：该函数在 `pmm_init` 的最开始被调用，它执行最基础的初始化工作：通过 `list_init(&free_list)` 初始化空闲块链表的头节点，使其成为一个空空的双向循环链表；并将全局的空闲页计数器 `nr_free` 置为 0。它为后续的内存管理准备了一个干净的“账本”。

2.  **`default_init_memmap(struct Page *base, size_t n)`**:
    *   **作用**：接收一块连续的、可用的物理内存，并将其作为一个大的初始空闲块加入到管理器中。
    *   **过程**：`page_init` 函数在探测并排除内核、PMM自身占用的内存后，会调用此函数。它首先将这 `n` 个页对应的 `Page` 结构体的 `flags` 和 `property` 清零，确保它们是“干净”的普通页。然后，它将这块连续内存的“头”页（`base`）的 `property` 设置为 `n`，表示这是一个大小为 `n` 的连续空闲块，并设置 `PG_property` 标志。最后，它会将这个头页的 `page_link` 节点插入到全局的 `free_list` 中，插入时会保持链表按物理地址**从小到大**的顺序，这对于后续的内存合并至关重要。

3.  **`default_alloc_pages(size_t n)`**:
    *   **作用**：实现 First-Fit 算法的**分配**逻辑。
    *   **过程**：
        a. 首先断言 `n > 0` 并检查请求的页数 `n` 是否超过当前总空闲页数 `nr_free`，若超过则无法分配，返回 `NULL`。
        b. 从 `free_list` 的头节点开始，**顺序遍历**整个空闲块链表。
        c. 对于每一个空闲块的头页 `p`，检查其大小 `p->property` 是否大于等于请求的大小 `n`。
        d. **一旦找到第一个满足条件的块**，就立即停止搜索（`break`）。
        e. 如果找到了这样的块 `page`：
            i.  将其从 `free_list` 中移除。
            ii. **判断是否需要分裂**：如果 `page->property > n`，说明这个块比需要的大。此时，将 `page` 之后的第 `n` 个页（即 `page + n`）设置为一个新的空闲块的头部，其大小为 `page->property - n`，并将其插回 `free_list`。
            iii. 更新总空闲页数 `nr_free -= n`。
            iv. 清除被分配出去的块 `page` 的 `PG_property` 标志位。
        f. 返回分配到的块的起始 `Page` 结构体指针 `page`。

4.  **`default_free_pages(struct Page *base, size_t n)`**:
    *   **作用**：实现 First-Fit 算法的**释放与合并**逻辑。
    *   **过程**：
        a. 首先，将被释放的 `n` 个页 `base` 标记为一个大小为 `n` 的新空闲块（设置 `property` 和 `PG_property`）。
        b. 将这个新空闲块按地址顺序插入到 `free_list` 中。
        c. **执行合并操作**：这是减少内存碎片的关键。
            i.  **向前合并**：检查新插入块 `base` 在链表中的**前一个**块 `p`。如果 `p` 和 `base` 在物理上是连续的（即 `p + p->property == base`），则将它们合并：将 `p` 的大小增加 `n`（`p->property += base->property`），并把 `base` 的节点从链表中删除。
            ii. **向后合并**：检查（可能已经合并过的）块 `base` 在链表中的**后一个**块 `p`。如果它们在物理上是连续的（即 `base + base->property == p`），则再次合并：将 `base` 的大小增加 `p` 的大小，并把 `p` 的节点从链表中删除。
        d. 更新总空闲页数 `nr_free += n`。

#### **2. First-Fit 算法的改进空间** 
First-Fit 算法虽然简单高效，但仍有明显的改进空间：

1.  **性能优化**：当系统中存在大量离散的空闲块时，每次分配都需要从头开始遍历链表，最坏情况下时间复杂度为 O(N)，其中 N 是空闲块的数量。可以引入**多级空闲链表 (Segregated Free Lists)**，即按空闲块的大小范围维护多个链表（如一个链表负责1-4页的块，另一个负责5-16页的块等）。分配时，只需在对应大小范围的链表中查找，能显著提高查找效率。

2.  **碎片问题**：First-Fit 倾向于在内存的低地址区域切割出许多小的、难以再利用的碎片，因为每次查找都从头开始。一个简单的改进是采用 **Next-Fit (下次适应)** 算法，即维护一个全局指针记录上次分配结束的位置，下次分配时从该指针处开始查找。这使得内存的消耗和碎片在整个地址空间中分布得更均匀。

3.  **数据结构优化**：使用**平衡二叉搜索树**（如红黑树）或**跳表**来组织空闲块，可以按地址或大小排序。如果按地址排序，可以 O(logN) 的时间复杂度找到插入点和相邻块，优化合并效率；如果按大小排序，则可以快速找到满足条件的块。


### **练习2：实现 Best-Fit 连续物理内存分配算法（需要编程）**

#### **1. 设计实现过程**
Best-Fit (最佳适应) 算法的目标是选择一个能满足请求、并且大小与请求大小最接近的空闲块，以期保留下更大的连续空闲块，减少因分裂产生的小碎片。

我们实现过程如下：

1.  在  `pmm.c` 中进行相应修改，将默认的物理内存管理器指向 `best_fit_pmm_manager`。

2.  Best-Fit 的核心改动仅在于**分配策略**。因此，`best_fit_init`、`best_fit_init_memmap` 和 `best_fit_free_pages` 函数的逻辑与 First-Fit 完全相同，可以直接复用。这是因为空闲链表的组织方式（按地址排序）和释放时的合并逻辑，与分配时如何选择块是解耦的。

3.  **重写分配函数 `best_fit_alloc_pages`**: 这是本次编程的核心。
    *   初始化两个变量：`struct Page *best_fit = NULL;` 用来记录当前找到的最佳块，`unsigned int min_size = nr_free + 1;` (或一个足够大的数) 用来记录最佳块的大小。
    *   与 First-Fit 不同，Best-Fit **必须遍历整个空闲链表**，而不能找到第一个就停止。
    *   在循环中，对于每个空闲块 `p`，进行判断：
        *   如果 `p->property >= n` (满足大小要求)
        *   并且 `p->property < min_size` (比当前找到的“最佳”块更“小”，即更接近)
        *   则更新 `best_fit = p;` 和 `min_size = p->property;`。
    *   循环结束后，`best_fit` 指针就指向了全局最优的那个块。
    *   后续的分裂、链表操作、更新计数器等逻辑，与 First-Fit 完全一致，只需将操作对象从 `page` 换成 `best_fit` 即可。


#### **2. 阐述代码如何分配和释放物理内存**
*   **分配 (`best_fit_alloc_pages`)**：
    当请求分配 `n` 页时，代码会扫描**所有**的空闲块。它会记住那个大小不小于 `n` 但又是所有满足条件的块中**最小**的一个。例如，如果空闲块有 {5页, 10页, 20页}，请求分配 4 页，Best-Fit 会选择 5 页的那个块。找到这个“最佳”块后，如果它的大小恰好为 `n`，则整个分配；如果大于 `n`，则分裂成 `n` 页（分配出去）和 `(size - n)` 页（作为新的更小的空闲块放回链表）。

*   **释放 (`best_fit_free_pages`)**：
    释放过程与 First-Fit 完全一样。当一块内存被释放时，代码会将其作为一个新的空闲块，并按其物理地址插入到空闲链表中。然后，它会检查这个新块是否能和它在物理地址上相邻的前一个或后一个空闲块合并。如果可以，就将它们合并成一个更大的连续空闲块。这个合并过程是减少外部碎片的关键，它与分配策略无关。

### 扩展练习Challenge1：buddy system（伙伴系统）分配算法（需要编程）

本组将 `pmm_manager` 切换至自研的 buddy 分配器，通过“2^k 粒度 + 伙伴合并”达到快速回收与低外碎片的目标：

- 初始化时按最大可容纳的 2^k 块拆分空闲区，填充 `free_area[0..MAX_ORDER]`；
- `alloc_pages` 计算目标阶并自顶向下拆分，`free_pages` 以 XOR 定位伙伴并循环合并；
- 自检覆盖基本分配、伙伴合并、边界条件与压力场景，QEMU 日志中可见 “Buddy System Comprehensive Test” 全部通过。

架构细节、关键伪代码与测试矩阵详见 `design_buddy.md`。

##### **4.2 性能对比分析**

| 操作   | Buddy System | First-Fit | Best-Fit |
|--------|--------------|-----------|----------|
| 分配   | O(log N)     | O(N)      | O(N)     |
| 释放   | O(log N)     | O(N)      | O(N)     |
| 合并   | **O(1)** ⚡   | O(N)      | O(N)     |

**时间复杂度说明**：
- **分配**: Buddy 最多需要遍历 MAX_ORDER 个链表并执行分裂，O(log N)
- **释放**: 最多向上合并 MAX_ORDER 次，每次合并是 O(1)，总计 O(log N)
- **合并**: XOR 计算伙伴地址是 O(1)，这是 Buddy 的最大优势

##### **4.3 空间碎片对比**

**内部碎片**（Buddy 的劣势）：

| 请求大小 | 实际分配 | 浪费率  |
|---------|---------|--------|
| 1 页    | 1 页    | 0%     |
| 3 页    | 4 页    | 25%    |
| 5 页    | 8 页    | 37.5%  |
| 7 页    | 8 页    | 12.5%  |
| 9 页    | 16 页   | 43.75% |
| **平均** | -      | **~20%** |

**外部碎片**（Buddy 的优势）：
- First-Fit 平均外部碎片率: 30-40%
- Best-Fit 外部碎片率: 25-35%（但产生大量小碎片）
- **Buddy System**: < 10%（快速合并机制有效抑制）


#### **5. 算法优缺点总结**

##### **优势** ✓

1. **合并速度极快**: O(1) 时间复杂度定位伙伴，远快于 First-Fit/Best-Fit 的 O(N) 遍历
2. **有效抑制外部碎片**: 递归合并机制能快速将小块聚合成大块
3. **实现简单**: 核心算法基于位运算，代码简洁易懂
4. **内存利用率可预测**: 2 的幂次分配，便于分析和优化

##### **劣势** ✗

1. **内部碎片严重**: 只能分配 2^k 大小，平均浪费约 20% 空间
2. **不适合小内存请求**: 请求 1 页和请求 2 页的开销相同
3. **固定粒度**: 无法灵活调整分配粒度

##### **适用场景**

**推荐使用**：
- 需要频繁分配/释放的场景（如页面交换）
- 需要保持大块内存可用性（如大规模 DMA）
- 对合并速度有严格要求的实时系统

**不推荐使用**：
- 内存极度紧张的嵌入式系统
- 分配请求普遍为奇数页的场景
- 对空间利用率要求极高的场景



#### **8. 扩展思考与改进方向**

##### **可能的优化**：

1. **懒惰合并（Lazy Coalescing）**
   - 延迟合并操作，减少频繁分配/释放时的开销
   - 定期或在内存压力大时批量合并

2. **混合策略**
   - 小块（< 16 页）用 Buddy System
   - 大块（≥ 16 页）用独立的大页分配器

3. **可配置 MAX_ORDER**
   - 根据系统内存大小动态调整
   - 小内存系统用较小的 MAX_ORDER 减少开销

4. **使用位图加速**
   - 用位图记录每个块的分配状态
   - 加速伙伴查找和合并判断

##### **学习价值**：

通过实现 Buddy System，我们深刻理解了：
- 内存管理中**时间与空间的权衡**
- **位运算在系统编程中的巧妙应用**
- **递归思想在算法设计中的威力**
- **测试驱动开发**的重要性

这些经验对理解现代操作系统的内存管理机制具有重要意义。

---
### 扩展练习Challenge2:

本组在 `buddy_pmm` 之上实现了一个轻量级的 SLUB 对象分配器，用于优化小对象频繁分配场景。

- 初始化阶段重置缓存池、调用 `buddy_init`，并通过 `kmem_cache_create` 建立 16~2048B 的固定尺寸缓存；
- 每个 `kmem_cache_t` 以单页 slab 为粒度，页首保存 `slab_t` 元数据，空闲对象通过单向链表串接；
- `kmalloc/kfree` 通过 `size_caches` 快速定位合适缓存，再复用 `kmem_cache_alloc/free` 完成对象管理，自检用例全部通过。

更完整的结构与流程说明见 `design_slub.md` 设计文档。


### 扩展练习Challenge3：

#### **问题定义**

在缺乏固件接口(如 Device Tree Blob 或 BIOS/UEFI 内存映射表)的情况下,操作系统内核需要自主确定系统中可用的物理内存区域。这要求内核能够区分:可读写的随机访问内存(RAM)、未映射的地址空间,以及内存映射 I/O (MMIO) 区域。

---

#### **技术原理**

采用**试探性读写验证**机制。从已知的安全内存地址(通常为内核加载区域)开始,通过系统性的探测操作来识别可用内存:

1. **地址空间扫描**:按固定步长(通常为物理页大小,如 4KB)遍历待探测的地址范围。

2. **读写验证序列**:对每个目标地址执行以下操作:
   - 读取并保存原始数据
   - 写入特定测试模式(魔数,如 `0xDEADBEEF`)
   - 回读并验证数据一致性
   - 写入第二个测试模式以排除地址线故障
   - 再次验证数据一致性
   - 恢复原始数据

3. **结果判定**:
   - 若所有验证通过,则该地址所在页面为可用 RAM
   - 若读写结果不一致,则该区域不可用或非标准 RAM
   - 若访问引发异常,则该地址空间未映射

4. **内存区域记录**:将连续的可用页面合并为内存区域描述符,构建完整的物理内存映射表。

---

#### **形式化描述**

```
算法:物理内存探测
输入:起始地址 start_addr,探测范围 range,步长 stride
输出:可用内存区域列表 memory_regions[]

for addr in range(start_addr, start_addr + range, stride):
    old_value ← READ(addr)
    
    WRITE(addr, MAGIC_1)
    if READ(addr) ≠ MAGIC_1:
        continue  // 非 RAM 区域
    
    WRITE(addr, MAGIC_2)
    if READ(addr) ≠ MAGIC_2:
        continue  // 验证失败
    
    WRITE(addr, old_value)  // 恢复原始数据
    
    mark_as_available(addr)

return merge_contiguous_regions(available_addresses)
```

**关键参数**:
- `MAGIC_1`, `MAGIC_2`:用于验证的测试模式,通常选择具有显著位模式的值(如 `0xDEADBEEF`, `0x5A5A5A5A`)
- `stride`:探测粒度,权衡探测精度与执行时间

---

#### **风险分析与缓解策略**

**主要风险**:

1. **MMIO 区域干扰**:向硬件寄存器写入测试数据可能触发不可预期的设备行为,导致系统不稳定或硬件状态异常。

2. **系统异常**:访问非法地址空间可能引发机器检查异常(Machine Check Exception, MCE)或总线错误。

**缓解措施**:

1. **异常处理机制**:在探测代码中实现健壮的异常处理程序,捕获并安全恢复 MCE、页面错误等异常。

2. **预定义排除区域**:基于硬件架构规范,维护已知 MMIO 区域的地址范围列表,在探测时主动跳过这些区域。

3. **保守探测策略**:
   - 使用多重验证模式降低误判概率
   - 采用非破坏性测试序列
   - 限制探测范围于合理的物理地址空间

4. **架构相关优化**:利用处理器特性(如 x86 的 MTRRs)辅助判断内存类型。


## **四、 总结**

本次实验围绕“页级 + 对象级”两条主线构建了完整的内核内存管理链路：先通过 First-Fit/Best-Fit 掌握基础页分配，再分别扩展了 Buddy 与 SLUB 系统以覆盖大块与小对象需求；Challenge3 则探索了固件缺失时的内存探测策略。所有功能均在 `make qemu` 自检中通过，关键实现与测试细节已拆分到 `design_buddy.md`、`design_slub.md` 等文档，便于后续维护与复用。


